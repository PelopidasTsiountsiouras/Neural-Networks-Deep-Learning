{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IAgz6QYzGlO",
        "outputId": "56ffce6d-9027-44aa-e91b-b06863ed40e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found models:\n",
            "  • MLP-Best_model.pth\n",
            "  • CNN-Best-100ep_model.pth\n",
            "  • CNN-Best-150ep_model.pth\n",
            "  • MLP-Small-256_model.pth\n",
            "  • MLP-Large-1024-512_model.pth\n",
            "  • MLP-512-LR001_model.pth\n",
            "\n",
            "Device: cuda\n",
            "\n",
            "Loading: MLP-Best_model.pth\n",
            "  → Train Accuracy: 60.53%\n",
            "\n",
            "Loading: CNN-Best-100ep_model.pth\n",
            "  → Train Accuracy: 94.19%\n",
            "\n",
            "Loading: CNN-Best-150ep_model.pth\n",
            "  → Train Accuracy: 95.21%\n",
            "\n",
            "Loading: MLP-Small-256_model.pth\n",
            "  → Train Accuracy: 50.26%\n",
            "\n",
            "Loading: MLP-Large-1024-512_model.pth\n",
            "  → Train Accuracy: 57.12%\n",
            "\n",
            "Loading: MLP-512-LR001_model.pth\n",
            "  → Train Accuracy: 51.79%\n",
            "\n",
            "============================================================\n",
            "TRAINING ACCURACY SUMMARY\n",
            "============================================================\n",
            "MLP-Best_model.pth                   60.53%\n",
            "CNN-Best-100ep_model.pth             94.19%\n",
            "CNN-Best-150ep_model.pth             95.21%\n",
            "MLP-Small-256_model.pth              50.26%\n",
            "MLP-Large-1024-512_model.pth         57.12%\n",
            "MLP-512-LR001_model.pth              51.79%\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "#   LOAD ALL SAVED MODELS (CORRECT ARCHITECTURES) + TRAIN ACC\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# MOUNT DRIVE\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "MODELS_DIR = \"/content/drive/MyDrive/NN_CIFAR10_Project\"\n",
        "model_files = [f for f in os.listdir(MODELS_DIR) if f.endswith(\".pth\")]\n",
        "\n",
        "print(\"Found models:\")\n",
        "for f in model_files:\n",
        "    print(\"  •\", f)\n",
        "\n",
        "# CIFAR-10 TRAINSET (same aug + normalization)\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform_train\n",
        ")\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"\\nDevice:\", device)\n",
        "\n",
        "# ARCHITECTURES\n",
        "\n",
        "class BestMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "    def forward(self, x): return self.network(x)\n",
        "\n",
        "class BestCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.dropout2d(x, 0.1, training=self.training)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.dropout2d(x, 0.2, training=self.training)\n",
        "\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = F.relu(self.bn6(self.conv6(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.dropout2d(x, 0.3, training=self.training)\n",
        "\n",
        "        return self.classifier(x)\n",
        "\n",
        "class ConfigurableMLP(nn.Module):\n",
        "    def __init__(self, hidden_sizes):\n",
        "        super().__init__()\n",
        "        layers = [nn.Flatten()]\n",
        "        in_size = 3072\n",
        "\n",
        "        for h in hidden_sizes:\n",
        "            layers += [\n",
        "                nn.Linear(in_size, h),\n",
        "                nn.BatchNorm1d(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.3)\n",
        "            ]\n",
        "            in_size = h\n",
        "\n",
        "        layers.append(nn.Linear(in_size, 10))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x): return self.network(x)\n",
        "\n",
        "# MAP FILENAMES → CORRECT ARCHITECTURE\n",
        "\n",
        "def build_model_for_file(filename):\n",
        "    if \"CNN\" in filename:\n",
        "        return BestCNN()\n",
        "    if filename.startswith(\"MLP-Best\"):\n",
        "        return BestMLP()\n",
        "    if \"MLP-Small-256\" in filename:\n",
        "        return ConfigurableMLP([256])\n",
        "    if \"MLP-Large-1024-512\" in filename:\n",
        "        return ConfigurableMLP([1024, 512])\n",
        "    if \"MLP-512-LR001\" in filename or \"MLP-512-LR01\" in filename:\n",
        "        return ConfigurableMLP([512])\n",
        "    raise ValueError(f\"Unknown model file: {filename}\")\n",
        "\n",
        "# TRAIN ACCURACY FUNCTION\n",
        "\n",
        "def compute_train_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# LOAD MODELS + COMPUTE ACCURACY\n",
        "\n",
        "results = {}\n",
        "\n",
        "for filename in model_files:\n",
        "    print(\"\\nLoading:\", filename)\n",
        "    path = f\"{MODELS_DIR}/{filename}\"\n",
        "\n",
        "    model = build_model_for_file(filename).to(device)\n",
        "    state = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "\n",
        "    acc = compute_train_accuracy(model, trainloader)\n",
        "    results[filename] = acc\n",
        "    print(f\"  → Train Accuracy: {acc:.2f}%\")\n",
        "\n",
        "# SUMMARY\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING ACCURACY SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "for name, acc in results.items():\n",
        "    print(f\"{name:<35} {acc:6.2f}%\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ]
}