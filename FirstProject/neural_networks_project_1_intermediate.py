# -*- coding: utf-8 -*-
"""Neural_Networks_Project_1_Intermediate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VGrUPMERx7KMZHjHBt9AEm9y2bWh9OcW

# **Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· ÎºÎ±Î¹ Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Î’Î¹Î²Î¹Î»Î¹Î¿Î¸Î·ÎºÏÎ½**

Î•Î³ÎºÎ±Î¸Î¹ÏƒÏ„Ï ÎºÎ±Î¹ ÎµÎ¹ÏƒÎ¬Î³Ï‰ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„ÎµÏ‚ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎµÏ‚ Î³Î¹Î± Ï„Î± Ï€ÎµÎ¹ÏÎ¬Î¼Î±Ï„Î± ÎºÎ±Î¹ Ï„Î± tests Ï€Î¿Ï… Î¸Î­Î»Ï‰ Î½Î± Ï„ÏÎ­Î¾Ï‰.
"""

import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
import time
import pickle
import urllib.request
import tarfile
import os
from google.colab import drive
from sklearn.decomposition import PCA
from matplotlib.patches import Patch

print("Libraries loaded successfully")

"""# **Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î”Î¹Î±Î³ÏÎ±Î¼Î¼Î¬Ï„Ï‰Î½ ÏƒÏ„Î¿ Google Drive**

"""

drive.mount('/content/drive')
save_path = '/content/drive/MyDrive/NeuralNetworks/Project1'
os.makedirs(save_path, exist_ok=True)

"""# **ÎšÎ±Ï„Î­Î²Î±ÏƒÎ¼Î± ÎºÎ±Î¹ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· CIFAR-10**

Î“Î¹Î± Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± ÎµÏ€Î­Î»ÎµÎ¾Î± Ï„Î¿ dataset **CIFAR-10**, ÎºÎ±Î¸ÏÏ‚ ÎµÎ¯Î½Î±Î¹ Î®Î´Î· Ï‡Ï‰ÏÎ¹ÏƒÎ¼Î­Î½Î¿ ÏƒÎµ ÏƒÏÎ½Î¿Î»Î¿ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ ÎºÎ±Î¹ ÎµÎ»Î­Î³Ï‡Î¿Ï… ÎºÎ±Î¹ Ï€Î±Î¯ÏÎ½Ï‰ Ï„Î¹Ï‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚ Ï‰Ï‚ Î­Î½Î± numpy array, Î³Î¹Î± Î½Î± Î¼Ï€Î¿ÏÎ­ÏƒÏ‰ Î½Î± Ï„Î¹Ï‚ Î´Î¹Î±Ï‡ÎµÎ¹ÏÎ¹ÏƒÏ„Ï ÎµÏ…ÎºÎ¿Î»ÏŒÏ„ÎµÏÎ±.
"""

def download_cifar10():

    """
    Downloads CIFAR-10 dataset
    """

    url = "https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
    filename = "cifar-10-python.tar.gz"

    if not os.path.exists(filename):
        print("Downloading CIFAR-10... (around 170MB)")
        urllib.request.urlretrieve(url, filename)
        print("Download completed!")

    # Decompression
    if not os.path.exists("cifar-10-batches-py"):
        print("Decompression...")
        with tarfile.open(filename, 'r:gz') as tar:
            tar.extractall()
        print("Decompression completed!")

def load_cifar10_batch(file):

    """
    Loads a batch of CIFAR-10

    """

    with open(file, 'rb') as f:
        batch = pickle.load(f, encoding='bytes')

    # Conversion from bytes to strings for the keys
    data = batch[b'data']
    labels = batch[b'labels']

    # Reshape: (10000, 3072) -> (10000, 3, 32, 32) -> (10000, 32, 32, 3)
    data = data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)

    return data, np.array(labels)

def load_cifar10(batch=5):

    """
    Loads the whole CIFAR-10 dataset
    parameters: batch: number of batches to load, default=5(the whole dataset)
    returns: traing data (X_train, y_train), test data (X_test, y_test), class names (class_names)
    """

    download_cifar10()

    # Training data
    X_train_list = []
    y_train_list = []

    if batch == 1:
      file = "cifar-10-batches-py/data_batch_1"
      X_batch, y_batch = load_cifar10_batch(file)
      X_train_list.append(X_batch)
      y_train_list.append(y_batch)
    else:
      for i in range(1, batch+1):
          file = f"cifar-10-batches-py/data_batch_{i}"
          X_batch, y_batch = load_cifar10_batch(file)
          X_train_list.append(X_batch)
          y_train_list.append(y_batch)

    X_train = np.vstack(X_train_list)
    y_train = np.hstack(y_train_list)

    # Test data
    X_test, y_test = load_cifar10_batch("cifar-10-batches-py/test_batch")

    # Class Names
    with open("cifar-10-batches-py/batches.meta", 'rb') as f:
        meta = pickle.load(f, encoding='bytes')
    class_names = [name.decode('utf-8') for name in meta[b'label_names']]

    return X_train, y_train, X_test, y_test, class_names

# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
print("\n" + "="*60)
print("Data Loaded")
print("="*60)

X_train, y_train, X_test, y_test, class_names = load_cifar10()

print(f"Training set: {X_train.shape[0]} images")
print(f"Test set: {X_test.shape[0]} images")
print(f"Image size: {X_train.shape[1]}x{X_train.shape[2]} pixels")
print(f"Classes: {class_names}")

"""# **Î•Î¾ÎµÏÎµÏÎ½Î·ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½**

Î¦Î¿ÏÏ„ÏÎ½Ï‰ ÎºÎ¬Ï€Î¿Î¹ÎµÏ‚ Ï„Ï…Ï‡Î±Î¯ÎµÏ‚ Ï†Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¯ÎµÏ‚ Î±Ï€ÏŒ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚ Ï„Î¿Ï… dataset ÎºÎ±Î¹ Î²Î»Î­Ï€Ï‰, ÎµÏ€Î¯ÏƒÎ·Ï‚, Ï€ÏŒÏƒÎµÏ‚ Ï†Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¯ÎµÏ‚ Î­Ï‡ÎµÎ¹ ÎºÎ¬Î¸Îµ ÎºÎ»Î¬ÏƒÎ· ÏƒÏ„Î¿ training set.
"""

def show_sample_images(X, y, class_names, n_per_class=5):

    """
    Displays examples for each class
    parameters: X: images, y: labels, class_names: list of class names

    """

    n_classes = len(class_names)
    fig, axes = plt.subplots(n_classes, n_per_class, figsize=(12, 20))

    for i in range(n_classes):
        # Find n_per_class images from class i
        indices = np.where(y == i)[0][:n_per_class]

        for j, idx in enumerate(indices):
            axes[i, j].imshow(X[idx])
            axes[i, j].axis('off')
            if j == 0:
                axes[i, j].set_title(class_names[i], fontsize=14, fontweight='bold', pad=10)

    plt.tight_layout()
    plt.suptitle('Examples from Each Class', fontsize=24, fontweight='bold', x=0.5, y=1.01)
    plt.savefig(f"{save_path}/sample_images.svg")
    plt.show()

print("\n" + "="*60)
print("DATA EXPLORING")
print("="*60)

show_sample_images(X_train, y_train, class_names, n_per_class=5)

# ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ»Î¬ÏƒÎµÏ‰Î½
unique, counts = np.unique(y_train, return_counts=True)
print("\nClass distribution in the training set:")
for cls, count in zip(unique, counts):
    print(f"   {class_names[cls]:12s}: {count} images")

"""# **Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½**

Î ÏÎ¿Ï„Î¿Ï Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸Î¿ÏÎ½ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·, ÎºÎ¬Î¸Îµ ÎµÎ¹ÎºÏŒÎ½Î± Î¼ÎµÏ„Î±Ï„ÏÎ¬Ï€Î·ÎºÎµ ÏƒÎµ Î¼Î¿Î½Î¿Î´Î¹Î¬ÏƒÏ„Î±Ï„Î¿ Î´Î¹Î¬Î½Ï…ÏƒÎ¼Î± 3072 ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Ï‰Î½ ÎºÎ±Î¹ Î¿Î¹ Ï„Î¹Î¼Î­Ï‚ Ï„Ï‰Î½ pixels ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎ±Î½ ÏƒÏ„Î¿ Î´Î¹Î¬ÏƒÏ„Î·Î¼Î± [0, 1]. Î¤Î± Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎ±Î½ Ï‰Ï‚ ÎµÎ¯ÏƒÎ¿Î´Î¿Ï‚ Î³Î¹Î± Ï„Î¿Ï…Ï‚ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…Ï‚ k-NN ÎºÎ±Î¹ NCC, ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Î½Ï„Î±Ï‚ Ï„Î·Î½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ® Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Ï„Ï‰Î½ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½.
"""

def preprocess_data(X_train, X_test):

    """
    Converts images to vectors and normalizes
    parameters: X_train (train data), X_test (test data)
    returns: X_train_flat (normalized train data), X_test_flat (normalized test data)
    """

    # Flatten: (N, 32, 32, 3) -> (N, 3072)
    X_train_flat = X_train.reshape(X_train.shape[0], -1).astype(np.float32)
    X_test_flat = X_test.reshape(X_test.shape[0], -1).astype(np.float32)

    # Normalization [0, 255] -> [0, 1]
    X_train_flat = X_train_flat / 255.0
    X_test_flat = X_test_flat / 255.0

    return X_train_flat, X_test_flat

print("\n" + "="*60)
print("PREPROCESS")
print("="*60)

X_train_flat, X_test_flat = preprocess_data(X_train, X_test)

print(f"Training shape: {X_train_flat.shape}")
print(f"Test shape: {X_test_flat.shape}")
print(f"Normalization: [{X_train_flat.min():.2f}, {X_train_flat.max():.2f}]")

"""# **Î¥Î»Î¿Ï€Î¿Î¹Î®ÏƒÎ· Î”Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏÎ½ Î‘Ï€Î¿ÏƒÏ„Î¬ÏƒÎµÏ‰Î½**

## Euclidean Distance
"""

def euclidean_distance(x1, x2):

    """
    Computes the Euclidean distance between two vectors x1,x2
    """

    return np.sqrt(np.sum((x1 - x2) ** 2))

"""## Manhattan Distance"""

def manhattan_distance_batch(X_test_point, X_train):

    """
    Manhattan distance (L1 norm) - more resistant to outliers

    """
    return np.sum(np.abs(X_train - X_test_point), axis=1)

"""## Cosine Distance"""

def cosine_distance_batch(X_test_point, X_train):

    """
    Cosine distance - measures angles instead of length
    """

    dot_product = np.dot(X_train, X_test_point)
    norm_test = np.linalg.norm(X_test_point)
    norm_train = np.linalg.norm(X_train, axis=1)
    cosine_sim = dot_product / (norm_train * norm_test + 1e-8)
    return 1 - cosine_sim

"""# **Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· Nearest Neighbor (1-NN ÎºÎ±Î¹ 3-NN)**"""

def knn_classifier(X_train, y_train, X_test, k=1, distance_type='euclidean'):
    """
    K-Nearest Neighbors Classifier

    parameters: X_train: Training data (N_train, D)
                y_train: Training labels (N_train,)
                X_test: Test data (N_test, D)
                k: number of neighbors (default=1)
                distance_type: 'euclidean', 'manhattan', Î® 'cosine' (default='euclidean')

    returns: predictions: Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î³Î¹Î± Ï„Î¿ test set (N_test,)
    """

    n_test = X_test.shape[0]
    n_train = X_train.shape[0]
    predictions = np.zeros(n_test, dtype=int)

    print(f"\nExcecution {k}-NN classifier ({distance_type} distance)...")
    print(f"Training samples: {n_train}")
    print(f"Test samples: {n_test}")

    start_time = time.time()

    for i in range(n_test):
        # Show progress every 1000 samples
        if (i + 1) % 1000 == 0:
            elapsed = time.time() - start_time
            print(f"   Processed {i+1}/{n_test} samples ({elapsed:.1f}s)")

        # Distance function choice
        if distance_type == 'manhattan':
            distances = manhattan_distance_batch(X_test[i], X_train)
        elif distance_type == 'cosine':
            distances = cosine_distance_batch(X_test[i], X_train)
        else:  # euclidean (default)
            distances = np.sqrt(np.sum((X_train - X_test[i]) ** 2, axis=1))

        # Find k nearest
        k_nearest_indices = np.argsort(distances)[:k]
        k_nearest_labels = y_train[k_nearest_indices]

        # Voting
        if k == 1:
            predictions[i] = k_nearest_labels[0]
        else:
            # Majority
            most_common = Counter(k_nearest_labels).most_common(1)
            predictions[i] = most_common[0][0]

    elapsed_time = time.time() - start_time
    print(f"Completed in {elapsed_time:.2f} seconds")

    return predictions

"""# **Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· Nearest Class Centroid (NCC)**"""

def ncc_classifier(X_train, y_train, X_test):

    """
    Nearest Class Centroid Classifier

    Calculates the center (average) of each class and categorizes
    based on the closest center
    parameters: X_train: training data (N_train, D)
                y_train: training labels (N_train,)
                X_test: test data (N_test, D)

    returns: predictions: predictions for the test set (N_test,)
    """
    n_classes = len(np.unique(y_train))
    n_features = X_train.shape[1]

    # Calculating class centers
    print("\n Calculating class centers...")
    centroids = np.zeros((n_classes, n_features))

    for c in range(n_classes):
        # Find all samples of class c
        class_samples = X_train[y_train == c]

        # Average Calculation
        centroids[c] = np.mean(class_samples, axis=0)
        print(f"Class {c} ({class_names[c]}): {class_samples.shape[0]} samples")

    # Classification of test samples
    print("\n Excecuting NCC classifier...")
    n_test = X_test.shape[0]
    predictions = np.zeros(n_test, dtype=int)

    start_time = time.time()

    for i in range(n_test):
        if (i + 1) % 1000 == 0:
            elapsed = time.time() - start_time
            print(f"Processed {i+1}/{n_test} samples ({elapsed:.1f}s)")

        # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î±Ï€ÏŒÏƒÏ„Î±ÏƒÎ·Ï‚ Î±Ï€ÏŒ ÏŒÎ»Î± Ï„Î± ÎºÎ­Î½Ï„ÏÎ±
        distances = np.sqrt(np.sum((centroids - X_test[i]) ** 2, axis=1))

        # Î Î»Î·ÏƒÎ¹Î­ÏƒÏ„ÎµÏÎ¿ ÎºÎ­Î½Ï„ÏÎ¿
        predictions[i] = np.argmin(distances)

    elapsed_time = time.time() - start_time
    print(f"Completed in {elapsed_time:.2f} seconds")

    return predictions

"""# **Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÎºÎ±Î¹ Î£ÏÎ³ÎºÏÎ¹ÏƒÎ·**

'ÎŸÎ»ÎµÏ‚ Î¿Î¹ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„ÎµÏ‚ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Ï„Î·Î½ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Ï„Ï‰Î½ Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÏ‰Î½, ÎºÎ±Î¸ÏÏ‚ ÎºÎ±Î¹ Î³Î¹Î± Ï„Î·Î½ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· ÎºÎ±Î¹ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Ï‰Î½ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Ï‰Î½ Î´Î¹Î±Î³ÏÎ±Î¼Î¼Î¬Ï„Ï‰Î½.
"""

def evaluate_classifier(y_true, y_pred, classifier_name):

    """
    Calculates performance metrics
    parameters: y_true: true labels (N,)
                y_pred: predicted labels (N,)
                classifier_name: name of the classifier
    returns: accuracy: accuracy of the classifier
    """

    accuracy = np.mean(y_true == y_pred) * 100

    print(f"\n{'='*60}")
    print(f"RESULTS: {classifier_name}")
    print(f"{'='*60}")
    print(f"Accuracy: {accuracy:.2f}%")
    print(f"Correct Predictions: {np.sum(y_true == y_pred)}/{len(y_true)}")

    # Per-class accuracy
    print(f"\n Accuracy per class:")
    for c in range(len(class_names)):
        mask = y_true == c
        if np.sum(mask) > 0:
            class_acc = np.mean(y_pred[mask] == y_true[mask]) * 100
            print(f"   {class_names[c]:12s}: {class_acc:.2f}%")

    return accuracy

def save_confusion_matrix(y_true, y_pred, class_names, title, filename):

  """
  Saves confusion matrix
  parameters: y_true: true labels (N,)
              y_pred: predicted labels (N,)
              class_names: list of class names
              title: title of the confusion matrix
              filename: name of the file to save
  """

  n_classes = len(class_names)
  cm = np.zeros((n_classes, n_classes), dtype=int)

  for true_label, pred_label in zip(y_true, y_pred):
      cm[true_label, pred_label] += 1

  full_path = f"{save_path}/{filename}"

  plt.figure(figsize=(10, 8))
  plt.imshow(cm, interpolation='nearest', cmap='Blues')
  plt.title(title)
  plt.colorbar()

  tick_marks = np.arange(n_classes)
  plt.xticks(tick_marks, class_names, rotation=45, ha='right')
  plt.yticks(tick_marks, class_names)

  plt.ylabel('True Label')
  plt.xlabel('Predicted Label')
  plt.tight_layout()
  plt.savefig(full_path, dpi=300, bbox_inches='tight')
  plt.show()

def plot_detailed_confusion_matrix(y_true, y_pred, class_names, title, model_name,
                                   save_folder="confusion_matrices"):

    """
    Draws and saves a detailed confusion matrix (with percentages) directly to Google Drive.

    Parameters:
        y_true (array): True labels (N,)
        y_pred (array): Predicted labels (N,)
        class_names (list): List of class names
        title (str): Plot title
        model_name (str): Short name of the model (used in filename)
        save_folder (str): Drive folder name (default: 'confusion_matrices')
    """

    # Compute confusion matrix
    n_classes = len(class_names)
    cm = np.zeros((n_classes, n_classes), dtype=int)
    for true_label, pred_label in zip(y_true, y_pred):
        cm[true_label, pred_label] += 1

    # Convert to percentages
    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

    # Plot
    fig, ax = plt.subplots(figsize=(12, 10))
    im = ax.imshow(cm_percent, cmap='RdYlGn', vmin=0, vmax=100)

    # Colorbar
    cbar = plt.colorbar(im, ax=ax)
    cbar.set_label('Accuracy (%)', rotation=270, labelpad=20)

    # Axes labels
    ax.set_xticks(np.arange(n_classes))
    ax.set_yticks(np.arange(n_classes))
    ax.set_xticklabels(class_names, rotation=45, ha='right')
    ax.set_yticklabels(class_names)

    # Text inside cells
    for i in range(n_classes):
        for j in range(n_classes):
            text_color = 'white' if cm_percent[i, j] < 50 else 'black'
            ax.text(j, i, f'{cm_percent[i, j]:.1f}%\n({cm[i, j]})',
                    ha='center', va='center', color=text_color, fontsize=8)

    ax.set_ylabel('True Label', fontsize=12)
    ax.set_xlabel('Predicted Label', fontsize=12)
    ax.set_title(title, fontsize=16, fontweight='bold')
    plt.tight_layout(rect=[0, 0, 1, 0.96])

    # Save to Drive
    filename = f"cm_detailed_{model_name}.svg"
    full_path = f"{save_path}/{filename}"
    plt.savefig(full_path, dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

    # Top-5 confusions
    print("\nTop-5 Most Frequent Confusions:")
    confusions = []
    for i in range(n_classes):
        for j in range(n_classes):
            if i != j:
                confusions.append((class_names[i], class_names[j], cm[i, j]))

    confusions.sort(key=lambda x: x[2], reverse=True)
    for true_c, pred_c, count in confusions[:5]:
        print(f"   {true_c:10s} â†’ {pred_c:10s}: {count} times")

"""# **Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Classifiers**

Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ classifiers Î³Î¹Î± Î½Î± ÎµÎ¾ÎµÏ„Î¬ÏƒÎ¿Ï…Î¼Îµ Ï„Î·Î½ Î±ÎºÏÎ¯Î²ÎµÎ¹Î¬ Ï„Î¿Ï…Ï‚ (accuracy) ÎºÎ±Î¸ÏÏ‚ ÎºÎ±Î¹ Ï„Ï‰Î½ Ï‡ÏÏŒÎ½Ï‰Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚. Î•Ï€Î¯ÏƒÎ·Ï‚, ÎµÎ¾ÎµÏ„Î¬ÏƒÎ±Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î±Ï€Î¿ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Ï€Î­ÏÎ± Î±Ï€ÏŒ Ï„Î·Î½ Î•Ï…ÎºÎ»Î¯Î´ÎµÎ¹Î±, Î³Î¹Î± Î½Î± Î´Î¿ÏÎ¼Îµ Î±Î½ Î¸Î± Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ· ÏƒÏ„Î·Î½ Î±ÎºÏÎ¯Î²ÎµÎ¹Î± ÎºÎ±Î¹ ÏƒÏ„Î¿Î½ Ï‡ÏÏŒÎ½Î¿ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚.

## Î•ÎºÏ„Î­Î»ÎµÏƒÎ· baseline classifiers (1-NN, 3-NN, NCC with Euclidean distance)
"""

print("\n" + "="*60)
print("START CLASSIFICATION")
print("="*60)
print("WARNING: This may take several minutes...") # You can reduce the test set for faster results

# For FAST testing, use a smaller subset
USE_SUBSET = False
SUBSET_SIZE = 10000  # Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ test samples

if USE_SUBSET:
    print(f"\n Using subset {SUBSET_SIZE} test samples for faster results")
    X_test_eval = X_test_flat[:SUBSET_SIZE]
    y_test_eval = y_test[:SUBSET_SIZE]
else:
    X_test_eval = X_test_flat
    y_test_eval = y_test

results = {}

print("\n" + "ğŸ”¹"*30)
print("BASELINE CLASSIFIERS (Euclidean Distance)")
print("ğŸ”¹"*30)

# 1-NN Classifier
pred_1nn = knn_classifier(X_train_flat, y_train, X_test_eval, k=1, distance_type='euclidean')
results['1-NN (Euclidean)'] = evaluate_classifier(y_test_eval, pred_1nn, "1-Nearest Neighbor (Euclidean)")

# 3-NN Classifier
pred_3nn = knn_classifier(X_train_flat, y_train, X_test_eval, k=3, distance_type='euclidean')
results['3-NN (Euclidean)'] = evaluate_classifier(y_test_eval, pred_3nn, "3-Nearest Neighbor (Euclidean)")

# NCC Classifier
pred_ncc = ncc_classifier(X_train_flat, y_train, X_test_eval)
results['NCC'] = evaluate_classifier(y_test_eval, pred_ncc, "Nearest Class Centroid")

"""Î’Î»Î­Ï€Î¿Ï…Î¼Îµ ÏŒÏ„Î¹ Î¼Îµ 1-NN classifier Î­Ï‡Î¿Ï…Î¼Îµ 35.39% accuracy Î±Î»Î»Î¬ Ï€Î¿Î»Ï Î¼ÎµÎ³Î¬Î»Î¿ Ï‡ÏÏŒÎ½Î¿ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ (3998.2 seconds), ÎµÎ½Ï Î¼Îµ 3-NN Î­Ï‡Î¿Ï…Î¼Îµ Ï€Î±ÏÏŒÎ¼Î¿Î¹Î¿ accuracy (35.61%) ÎºÎ±Î¹ ÎµÎ»Î±Ï†ÏÏÏ‚ Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ¿ Ï‡ÏÏŒÎ½Î¿ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ (3722.56 seconds). ÎœÎµ NCC classifier Î· Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Î¼ÎµÎ¹ÏÎ½ÎµÏ„Î±Î¹ Î±ÏÎºÎµÏ„Î¬ (27.74%) Î±Î»Î»Î¬ Î¿ Ï‡ÏÏŒÎ½Î¿Ï‚ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ ÎµÎ¯Î½Î±Î¹ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬ Ï€Î¹Î¿ Î¼Î¹ÎºÏÏŒÏ‚ (1.34 seconds).

## Distance Metrics
"""

# EXPERIMENT 1: DISTANCE METRICS (3-NN)
print("\n" + "ğŸ”¹"*30)
print("EXPERIMENT: DISTANCE METRICS")
print("ğŸ”¹"*30)
print("Comparison of different distance metrics with 3-NN")

# Manhattan Distance
pred_3nn_manhattan = knn_classifier(X_train_flat, y_train, X_test_eval, k=3, distance_type='manhattan')
results['3-NN (Manhattan)'] = evaluate_classifier(y_test_eval, pred_3nn_manhattan, "3-NN with Manhattan Distance")

# Cosine Distance
pred_3nn_cosine = knn_classifier(X_train_flat, y_train, X_test_eval, k=3, distance_type='cosine')
results['3-NN (Cosine)'] = evaluate_classifier(y_test_eval, pred_3nn_cosine, "3-NN with Cosine Distance")

"""Î ÏÎ¿ÏƒÏ€Î±Î¸ÏÎ½Ï„Î±Ï‚ Î½Î± Î¼ÎµÎ¹ÏÏƒÎ¿Ï…Î¼Îµ Ï„Î¿Î½ Ï‡ÏÏŒÎ½Î¿ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ (ÏŒÏ‡Î¹ ÏŒÎ¼Ï‰Ï‚ ÎµÎ¹Ï‚ Î²Î¬ÏÎ¿Ï‚ Ï„Î¿Ï… accuracy) Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÎ±Î¼Îµ Î½Î± Ï„ÏÎ­Î¾Î¿Ï…Î¼Îµ Ï„Î¿Î½ 3-NN classifier Î¼Îµ Î´ÏÎ¿ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î±Ï€Î¿ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ (Manhattan ÎºÎ±Î¹ cosine). ÎœÎµ Ï„Î· Ï‡ÏÎ®ÏƒÎ· Ï„Î·Ï‚ Î±Ï€ÏŒÏƒÏ„Î±ÏƒÎ·Ï‚ Manhattan Î±Ï…Î¾Î®Î¸Î·ÎºÎµ ÎµÎ»Î±Ï†ÏÏÏ‚ Ï„Î¿ accuracy ÎºÎ±Ï„Î¬ 3.61% Î±Î»Î»Î¬ Î±Ï…Î¾Î®Î¸Î·ÎºÎµ Ï…Ï€ÎµÏÎ²Î¿Î»Î¹ÎºÎ¬ ÎºÎ±Î¹ Î¿ Ï‡ÏÏŒÎ½Î¿Ï‚ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ (5130.59 seconds). ÎœÎµ Ï„Î·Î½ Ï‡ÏÎ®ÏƒÎ· Ï„Î·Ï‚ Î±Ï€ÏŒÏƒÏ„Î±ÏƒÎ·Ï‚ cosine Î±Ï…Î¾Î®Î¸Î·ÎºÎµ ÎµÎ»Î±Ï†ÏÏÏ‚ Ï„Î¿ accuracy (37.74%) ÎµÎ½Ï Ï€Î±ÏÎ¬Î»Î»Î·Î»Î± Î¼ÎµÎ¹ÏÎ¸Î·ÎºÎµ ÎºÎ±Î¹ Î¿ Ï‡ÏÏŒÎ½Î¿Ï‚ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ (3544.48 seconds).

## PCA Analysis
"""

# EXPERIMENT 3: PCA ANALYSIS
print("\n" + "ğŸ”¹"*30)
print("EXPERIMENT: PRINCIPAL COMPONENT ANALYSIS (PCA)")
print("ğŸ”¹"*30)
print("Dimension reduction for faster processing")

# We try a few basic settings
pca_configs = [25, 50, 100]
pca_results = {}

for n_components in pca_configs:
    print(f"\n{'â”€'*60}")
    print(f"Testing PCA with {n_components} components")
    print(f"{'â”€'*60}")

    # Implementation PCA
    pca = PCA(n_components=n_components)
    X_train_pca = pca.fit_transform(X_train_flat)
    X_test_pca = pca.transform(X_test_eval)

    explained_var = pca.explained_variance_ratio_.sum() * 100
    print(f"Explained variance: {explained_var:.2f}%")
    print(f"Dimensions: {X_train_flat.shape[1]} â†’ {n_components}")

    # Test with 1-NN
    pred_pca = knn_classifier(X_train_pca, y_train, X_test_pca, k=1, distance_type='euclidean')
    acc = evaluate_classifier(y_test_eval, pred_pca, f"1-NN with PCA-{n_components}")

    pca_results[f'1-NN (PCA-{n_components})'] = {
        'accuracy': acc,
        'explained_var': explained_var,
        'n_components': n_components
    }
    results[f'1-NN (PCA-{n_components})'] = acc

"""Î’Î»Î­Ï€Î¿Î½Ï„Î±Ï‚ ÏŒÏ„Î¹ Î¿ÏÏ„Îµ Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î±Ï€Î¿ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Î¼ÎµÎ¹ÏÎ¸Î·ÎºÎµ Î¿ Ï‡ÏÏŒÎ½Î¿Ï‚ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÎ±Î¼Îµ Ï„Î· Ï‡ÏÎ®ÏƒÎ· Ï„Î·Ï‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ®Ï‚ PCA ÏƒÏ„Î¿Î½ 1-NN classifier. ÎœÎµÎ¹ÏÎ½Î¿Î½Ï„Î±Ï‚ Ï„Î± Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î±Ï€ÏŒ 3072 ÏƒÎµ 25â€“100 ÏƒÏ…Î½Î¹ÏƒÏ„ÏÏƒÎµÏ‚ Î´Î¹Î±Ï„Î®ÏÎ·ÏƒÎµ 77â€“90% Ï„Î·Ï‚ Î´Î¹Î±ÎºÏÎ¼Î±Î½ÏƒÎ·Ï‚, Î¼Îµ Ï„Î¿Î½ Ï‡ÏÏŒÎ½Î¿ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ Î½Î± Î±Ï…Î¾Î¬Î½ÎµÏ„Î±Î¹ ÏŒÏƒÎ¿ Î±Ï…Î¾Î¬Î½Î¿Î½Ï„Î±Î¹ Î¿Î¹ ÏƒÏ…Î½Î¹ÏƒÏ„ÏÏƒÎµÏ‚. Î— Î±ÎºÏÎ¯Î²ÎµÎ¹Î± Ï„Î¿Ï… Ï„Î±Î¾Î¹Î½Î¿Î¼Î·Ï„Î® 1-NN Ï€Î±ÏÎ­Î¼ÎµÎ¹Î½Îµ ÏƒÏ‡ÎµÎ´ÏŒÎ½ ÏƒÏ„Î±Î¸ÎµÏÎ® (â‰ˆ38â€“39%), Î´ÎµÎ¯Ï‡Î½Î¿Î½Ï„Î±Ï‚ ÏŒÏ„Î¹ Ï€Î­ÏÎ± Î±Ï€ÏŒ Ï„Î¹Ï‚ 50 ÏƒÏ…Î½Î¹ÏƒÏ„ÏÏƒÎµÏ‚ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î¿Ï…ÏƒÎ¹Î±ÏƒÏ„Î¹ÎºÎ¬ Î¿Ï†Î­Î»Î·. Î£Ï…Î½ÎµÏ€ÏÏ‚, Ï„Î¿ PCA ÏƒÏ…Î¼Ï€Î¹Î­Î¶ÎµÎ¹ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ¬ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±, Î±Î»Î»Î¬ Î¿Î¹ Î±Ï€Î»Î¿Î¯ Ï„Î±Î¾Î¹Î½Î¿Î¼Î·Ï„Î­Ï‚ Î±Ï€ÏŒÏƒÏ„Î±ÏƒÎ·Ï‚ Î´ÎµÎ½ Î±Î¾Î¹Î¿Ï€Î¿Î¹Î¿ÏÎ½ Ï€Î»Î®ÏÏ‰Ï‚ Ï„Î¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… Î´Î¹Î±Ï„Î·ÏÎ¿ÏÎ½Ï„Î±Î¹.

# **Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ¬ Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±**
"""

# COMPARATIVE ANALYSIS - VISUALIZATION

print("\n" + "="*60)
print("COMPARATIVE ANALYSIS")
print("="*60)

# RESULTS COLLECTION

results = {}
all_predictions = {}

"""## Baseline Classifiers"""

# Baseline Classifiers
print("\n" + "ğŸ”¹"*30)
print("BASELINE CLASSIFIERS (Euclidean Distance)")
print("ğŸ”¹"*30)

# 1-NN
results['1-NN (Euclidean)'] = evaluate_classifier(y_test_eval, pred_1nn, "1-Nearest Neighbor (Euclidean)")
all_predictions['1-NN'] = pred_1nn

# 3-NN
results['3-NN (Euclidean)'] = evaluate_classifier(y_test_eval, pred_3nn, "3-Nearest Neighbor (Euclidean)")
all_predictions['3-NN'] = pred_3nn

# NCC
results['NCC'] = evaluate_classifier(y_test_eval, pred_ncc, "Nearest Class Centroid")
all_predictions['NCC'] = pred_ncc

"""## Distance Metrics"""

# Distance Metrics Experiments
print("\n" + "ğŸ”¹"*30)
print("EXPERIMENT: DISTANCE METRICS")
print("ğŸ”¹"*30)

# Manhattan
results['3-NN (Manhattan)'] = evaluate_classifier(y_test_eval, pred_3nn_manhattan, "3-NN with Manhattan Distance")
all_predictions['3-NN-Manhattan'] = pred_3nn_manhattan

# Cosine
results['3-NN (Cosine)'] = evaluate_classifier(y_test_eval, pred_3nn_cosine, "3-NN with Cosine Distance")
all_predictions['3-NN-Cosine'] = pred_3nn_cosine

"""## PCA Experiments"""

# PCA Experiments
print("\n" + "ğŸ”¹"*30)
print("Î Î•Î™Î¡Î‘ÎœÎ‘: PRINCIPAL COMPONENT ANALYSIS (PCA)")
print("ğŸ”¹"*30)

pca_configs = [25, 50, 100]
pca_results = {}

for n_components in pca_configs:
    print(f"\n{'â”€'*60}")
    print(f"Testing PCA with {n_components} components")
    print(f"{'â”€'*60}")

    # Test with 1-NN
    acc = evaluate_classifier(y_test_eval, pred_pca, f"1-NN with PCA-{n_components}")

    pca_results[f'1-NN (PCA-{n_components})'] = {
        'accuracy': acc,
        'explained_var': explained_var,
        'n_components': n_components
    }
    results[f'1-NN (PCA-{n_components})'] = acc
    all_predictions[f'1-NN-PCA-{n_components}'] = pred_pca

"""## Confusion Matrixes"""

# CONFUSION MATRICES

print("\n" + "="*60)
print("GENERATING CONFUSION MATRICES")
print("="*60)

# Baseline confusion matrices (simple)
print("Confusion Matrix: 1-NN")
save_confusion_matrix(y_test_eval, pred_1nn, class_names,
                     "Confusion Matrix: 1-NN", "cm_1nn.svg")

print("Confusion Matrix: 3-NN")
save_confusion_matrix(y_test_eval, pred_3nn, class_names,
                     "Confusion Matrix: 3-NN", "cm_3nn.svg")

print("Confusion Matrix: NCC")
save_confusion_matrix(y_test_eval, pred_ncc, class_names,
                     "Confusion Matrix: NCC", "cm_ncc.svg")

# Detailed confusion matrices (with percentages)
print("\nGenerating detailed confusion matrices...")


print("Detailed Confusion Matrix: 1-NN Classifier")
plot_detailed_confusion_matrix(y_test_eval, pred_1nn, class_names,
                              "Detailed Confusion Matrix: 1-NN Classifier",
                              "1nn")

print("Detailed Confusion Matrix: 3-NN Classifier (Euclidean)")
plot_detailed_confusion_matrix(y_test_eval, pred_3nn, class_names,
                              "Detailed Confusion Matrix: 3-NN Classifier (Euclidean)",
                              "3nn_euclidean")

print("Detailed Confusion Matrix: 3-NN Classifier (Manhattan)")
plot_detailed_confusion_matrix(y_test_eval, pred_3nn_manhattan, class_names,
                              "Detailed Confusion Matrix: 3-NN Classifier (Manhattan)",
                              "3nn_manhattan")

print("Detailed Confusion Matrix: 3-NN Classifier (Cosine)")
plot_detailed_confusion_matrix(y_test_eval, pred_3nn_cosine, class_names,
                              "Detailed Confusion Matrix: 3-NN Classifier (Cosine)",
                              "3nn_cosine")

print("Detailed Confusion Matrix: NCC Classifier")
plot_detailed_confusion_matrix(y_test_eval, pred_ncc, class_names,
                              "Detailed Confusion Matrix: NCC Classifier",
                              "ncc")

# PCA confusion matrices (only the best)
best_pca_key = max(pca_results, key=lambda k: pca_results[k]['accuracy'])
best_pca_pred = all_predictions[best_pca_key.replace(' ', '-').replace('(', '').replace(')', '')]
best_pca_n = pca_results[best_pca_key]['n_components']

print(f"\nDetailed Confusion Matrix: 1-NN with PCA-{best_pca_n}")
plot_detailed_confusion_matrix(y_test_eval, best_pca_pred, class_names,
                              f"Detailed Confusion Matrix: 1-NN with PCA-{best_pca_n}",
                              f"1nn_pca{best_pca_n}")

"""## Custom Plots

### PLOT 1: BASELINE COMPARISON
"""

print("\nCreating Plot 1: Baseline Classifiers...")

fig, ax = plt.subplots(figsize=(10, 6))

baseline_names = ['1-Nearest\nNeighbor', '3-Nearest\nNeighbor', 'Nearest Class\nCentroid']
baseline_accs = [results[m] for m in baseline_methods]
baseline_colors = ['#3498db', '#2ecc71', '#e74c3c']

bars = ax.bar(baseline_names, baseline_accs, color=baseline_colors,
              alpha=0.85, edgecolor='black', linewidth=2, width=0.6)

ax.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')
ax.set_title('Baseline Classifiers Performance (Euclidean Distance)',
             fontsize=15, fontweight='bold', pad=20)
ax.set_ylim([0, max(baseline_accs) * 1.2])
ax.grid(axis='y', alpha=0.3, linestyle='--', linewidth=1.5)

# Add values
for i, bar in enumerate(bars):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height + 1,
            f'{height:.2f}%',
            ha='center', va='bottom', fontsize=13, fontweight='bold',
            bbox=dict(boxstyle='round,pad=0.3', facecolor='white',
                     edgecolor='black', linewidth=1.5))

# Random guess line
ax.axhline(y=10, color='red', linestyle=':', alpha=0.5, linewidth=2)
ax.text(2.5, 11, 'Random Guess (10%)', ha='right', fontsize=10,
        style='italic', color='red')

plt.tight_layout()
full_path = f"{save_path}/baseline_comparison.svg"
plt.savefig(full_path, dpi=300, bbox_inches='tight')
print(f"Saved: baseline_comparison.svg")
plt.show()

"""### PLOT 2: DISTANCE METRICS COMPARISON"""

print("\nCreating Plot 2: Distance Metrics Comparison...")

fig, ax = plt.subplots(figsize=(11, 6))

distance_names = ['Euclidean\n(L2 Norm)', 'Manhattan\n(L1 Norm)', 'Cosine\n(Angular)']
distance_full_methods = ['3-NN (Euclidean)', '3-NN (Manhattan)', '3-NN (Cosine)']
distance_accs = [results[m] for m in distance_full_methods]
colors_dist = ['#3498db', '#e74c3c', '#f39c12']

bars = ax.bar(distance_names, distance_accs, color=colors_dist,
              alpha=0.85, edgecolor='black', linewidth=2, width=0.5)

ax.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')
ax.set_title('Impact of Distance Metrics on 3-NN Performance',
             fontsize=15, fontweight='bold', pad=20)
ax.set_ylim([min(distance_accs) * 0.63, max(distance_accs) * 1.08])
ax.grid(axis='y', alpha=0.3, linestyle='--', linewidth=1.5)

# Add values
for i, bar in enumerate(bars):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height + 0.2,
            f'{height:.2f}%',
            ha='center', va='bottom', fontsize=12, fontweight='bold',
            bbox=dict(boxstyle='round,pad=0.3', facecolor='white',
                     edgecolor='black', linewidth=1.5))

# Add difference from baseline
baseline_euclidean = distance_accs[0]
for i, (bar, acc) in enumerate(zip(bars[1:], distance_accs[1:]), 1):
    diff = acc - baseline_euclidean
    color = 'green' if diff > 0 else 'red'
    symbol = '+' if diff >= 0 else ''
    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() * 0.5,
            f'{symbol}{diff:.2f}%',
            ha='center', va='center', fontsize=11, fontweight='bold',
            color=color, style='italic')

# Annotation
ax.text(0.02, 0.98, 'Baseline: Euclidean', transform=ax.transAxes,
        fontsize=10, verticalalignment='top',
        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))

plt.margins(y=0)
plt.tight_layout()
full_path = f"{save_path}/distance_metrics_comparison.svg"
plt.savefig(full_path, dpi=300, bbox_inches='tight')
print(f"Saved: distance_metrics_comparison.svg")
plt.show()

"""### PLOT 3: PCA DETAILED ANALYSIS (4 subplots)"""

print("\nCreating Plot 3: PCA Detailed Analysis...")

fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

# Prepare PCA data
pca_components = [pca_results[k]['n_components'] for k in pca_methods]
pca_accuracies = [pca_results[k]['accuracy'] for k in pca_methods]
pca_variances = [pca_results[k]['explained_var'] for k in pca_methods]
original_acc = results['1-NN (Euclidean)']

# Add original (no PCA)
pca_components_full = [3072] + pca_components
pca_accuracies_full = [original_acc] + pca_accuracies
pca_variances_full = [100.0] + pca_variances

# â”€â”€â”€ Subplot 1: Accuracy vs Components â”€â”€â”€
ax1.plot(pca_components_full, pca_accuracies_full, 'o-',
         linewidth=3, markersize=10, color='#2ecc71', markeredgecolor='black',
         markeredgewidth=2, label='1-NN Accuracy')
ax1.axhline(y=original_acc, color='red', linestyle='--', linewidth=2,
            alpha=0.5, label=f'Baseline (no PCA): {original_acc:.2f}%')

ax1.set_xlabel('Number of PCA Components', fontsize=12, fontweight='bold')
ax1.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')
ax1.set_title('(A) Accuracy vs Dimensionality', fontsize=13, fontweight='bold')
ax1.set_xscale('log')
ax1.grid(True, alpha=0.3, linestyle='--')
ax1.legend(loc='lower right', fontsize=10)

# Annotate key points
for comp, acc in zip(pca_components_full, pca_accuracies_full):
    if comp in [50, 100, 200, 3072]:
        ax1.annotate(f'{comp}\n{acc:.1f}%',
                    xy=(comp, acc), xytext=(10, 10),
                    textcoords='offset points', fontsize=9,
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),
                    arrowprops=dict(arrowstyle='->', lw=1.5))

# â”€â”€â”€ Subplot 2: Explained Variance â”€â”€â”€
ax2.plot(pca_components, pca_variances, 's-',
         linewidth=3, markersize=10, color='#9b59b6', markeredgecolor='black',
         markeredgewidth=2)
ax2.axhline(y=90, color='orange', linestyle='--', linewidth=2, alpha=0.6,
            label='90% threshold')
ax2.axhline(y=95, color='red', linestyle='--', linewidth=2, alpha=0.6,
            label='95% threshold')

ax2.set_xlabel('Number of PCA Components', fontsize=12, fontweight='bold')
ax2.set_ylabel('Explained Variance (%)', fontsize=12, fontweight='bold')
ax2.set_title('(B) Information Retention', fontsize=13, fontweight='bold')
ax2.set_xscale('log')
ax2.set_ylim([80, 102])
ax2.grid(True, alpha=0.3, linestyle='--')
ax2.legend(loc='lower right', fontsize=10)

# Annotate
for comp, var in zip(pca_components, pca_variances):
    if comp in [50, 100]:
        ax2.annotate(f'{var:.1f}%',
                    xy=(comp, var), xytext=(10, -15),
                    textcoords='offset points', fontsize=9,
                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

# â”€â”€â”€ Subplot 3: Accuracy Loss â”€â”€â”€
accuracy_losses = [original_acc - acc for acc in pca_accuracies]

bars = ax3.bar(range(len(pca_components)), accuracy_losses,
              color=['#e74c3c' if loss > 2 else '#2ecc71' for loss in accuracy_losses],
              alpha=0.85, edgecolor='black', linewidth=2)

ax3.axhline(y=2, color='red', linestyle='--', linewidth=2, alpha=0.6,
           label='2% loss threshold')
ax3.set_xlabel('PCA Configuration', fontsize=12, fontweight='bold')
ax3.set_ylabel('Accuracy Loss (%)', fontsize=12, fontweight='bold')
ax3.set_title('(C) Accuracy Degradation', fontsize=13, fontweight='bold')
ax3.set_xticks(range(len(pca_components)))
ax3.set_xticklabels([f'{c}\ncomp' for c in pca_components], fontsize=9)
ax3.grid(axis='y', alpha=0.3, linestyle='--')
ax3.legend(loc='upper left', fontsize=10)

# Add values
for i, (bar, loss) in enumerate(zip(bars, accuracy_losses)):
    ax3.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.1,
            f'{loss:.2f}%',
            ha='center', va='bottom', fontsize=10, fontweight='bold')

# â”€â”€â”€ Subplot 4: Dimensionality Reduction â”€â”€â”€
dimension_reduction = [(3072 - c) / 3072 * 100 for c in pca_components]

bars = ax4.bar(range(len(pca_components)), dimension_reduction,
              color='#3498db', alpha=0.85, edgecolor='black', linewidth=2)

ax4.set_xlabel('PCA Configuration', fontsize=12, fontweight='bold')
ax4.set_ylabel('Dimensionality Reduction (%)', fontsize=12, fontweight='bold')
ax4.set_title('(D) Compression Rate', fontsize=13, fontweight='bold')
ax4.set_xticks(range(len(pca_components)))
ax4.set_xticklabels([f'{c}' for c in pca_components], fontsize=9)
ax4.set_ylim([0, 100])
ax4.grid(axis='y', alpha=0.3, linestyle='--')

# Add values
for i, (bar, reduction) in enumerate(zip(bars, dimension_reduction)):
    ax4.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 2,
            f'{reduction:.1f}%',
            ha='center', va='bottom', fontsize=10, fontweight='bold')
    # Compression ratio
    ratio = 3072 / pca_components[i]
    ax4.text(bar.get_x() + bar.get_width()/2., bar.get_height() / 2,
            f'{ratio:.1f}x',
            ha='center', va='center', fontsize=11, fontweight='bold',
            color='white', style='italic')

plt.suptitle('Principal Component Analysis (PCA) - Comprehensive Evaluation',
             fontsize=16, fontweight='bold', y=0.995)
plt.tight_layout()
full_path = f"{save_path}/pca_detailed_analysis.svg"
plt.savefig(full_path, dpi=300, bbox_inches='tight')
print(f"Saved: pca_detailed_analysis.svg")
plt.show()

"""### PLOT 4: COMPLETE COMPARISON (All methods)"""

print("\nCreating Plot 4: Complete Methods Comparison...")

fig, ax = plt.subplots(figsize=(16, 7))

all_methods = baseline_methods + distance_methods + pca_methods
all_accuracies = [results[m] for m in all_methods]

# Colors and patterns
colors = []
edge_colors = []
hatches = []

for m in all_methods:
    if m in baseline_methods:
        colors.append('#3498db')
        edge_colors.append('darkblue')
        hatches.append('')
    elif m in distance_methods:
        colors.append('#e74c3c')
        edge_colors.append('darkred')
        hatches.append('//')
    else:  # PCA
        colors.append('#2ecc71')
        edge_colors.append('darkgreen')
        hatches.append('\\\\')

# Create bars
x_pos = np.arange(len(all_methods))
bars = ax.bar(x_pos, all_accuracies, color=colors,
              alpha=0.85, edgecolor=edge_colors, linewidth=2, width=0.7)

# Add patterns
for bar, hatch in zip(bars, hatches):
    bar.set_hatch(hatch)

ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')
ax.set_xlabel('Classification Method', fontsize=14, fontweight='bold')
ax.set_title('Comprehensive Comparison: All Classification Methods',
             fontsize=16, fontweight='bold', pad=20)
ax.set_xticks(x_pos)
ax.set_xticklabels([m.replace(' (', '\n(').replace(')', ')') for m in all_methods],
                   rotation=45, ha='right', fontsize=9)
ax.set_ylim([0, max(all_accuracies) * 1.15])
ax.grid(axis='y', alpha=0.3, linestyle='--', linewidth=1.5)

# Add values
for i, (bar, acc) in enumerate(zip(bars, all_accuracies)):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
            f'{acc:.1f}%',
            ha='center', va='bottom', fontsize=9, fontweight='bold',
            bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))

# Highlight best method
best_idx = all_accuracies.index(max(all_accuracies))
bars[best_idx].set_edgecolor('gold')
bars[best_idx].set_linewidth(4)
ax.annotate('â˜… BEST', xy=(best_idx, all_accuracies[best_idx]),
            xytext=(0, 20), textcoords='offset points',
            ha='center', fontsize=12, fontweight='bold', color='gold',
            bbox=dict(boxstyle='round,pad=0.5', facecolor='black', alpha=0.8),
            arrowprops=dict(arrowstyle='->', lw=2, color='gold'))

# Legend
legend_elements = [
    Patch(facecolor='#3498db', edgecolor='darkblue', linewidth=2,
          label='Baseline Algorithms'),
    Patch(facecolor='#e74c3c', edgecolor='darkred', linewidth=2, hatch='//',
          label='Distance Variants (3-NN)'),
    Patch(facecolor='#2ecc71', edgecolor='darkgreen', linewidth=2, hatch='\\\\',
          label='PCA-Reduced (1-NN)')
]
ax.legend(handles=legend_elements, loc='upper right', fontsize=11,
          framealpha=0.95, edgecolor='black', fancybox=True, shadow=True)

# Statistics
stats_text = f"Total Methods: {len(all_methods)}\n"
stats_text += f"Best: {max(all_accuracies):.2f}%\n"
stats_text += f"Worst: {min(all_accuracies):.2f}%\n"
stats_text += f"Range: {max(all_accuracies) - min(all_accuracies):.2f}%"

ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
        fontsize=10, verticalalignment='top', fontfamily='monospace',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8,
                 edgecolor='black', linewidth=2))

plt.tight_layout()
full_path = f"{save_path}/complete_methods_comparison.svg"
plt.savefig(full_path, dpi=300, bbox_inches='tight')
print(f"Saved: complete_methods_comparison.svg")
plt.show()

"""# **Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î± ÎŸÏÎ¸Î®Ï‚ ÎºÎ±Î¹ Î•ÏƒÏ†Î±Î»Î¼Î­Î½Î·Ï‚ ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯ÏƒÎ·ÏƒÎ·Ï‚**"""

def show_classification_examples(X_test, y_test, y_pred, class_names,
                                 correct=True, n_examples=5,
                                 model_name="model"):

    """
    Shows examples of correct or incorrect classification and saves to Google Drive.
    Parameters:
        X_test: test images (N_test, H, W, C)
        y_test: true labels (N_test,)
        y_pred: predicted labels (N_test,)
        class_names: list of class names
        correct: True for correct classifications, False for incorrect
        n_examples: number of examples to show
        model_name: short name to identify which model produced results
    """

    # Choose which examples to display
    if correct:
        indices = np.where(y_test == y_pred)[0]
        title = f"Examples of CORRECT Classification ({model_name})"
        color = 'green'
        prefix = "correct"
    else:
        indices = np.where(y_test != y_pred)[0]
        title = f"Examples of INCORRECT Classification ({model_name})"
        color = 'red'
        prefix = "incorrect"

    # Randomly choose subset
    if len(indices) > n_examples:
        indices = np.random.choice(indices, n_examples, replace=False)

    # Create plot
    fig, axes = plt.subplots(1, len(indices), figsize=(15, 3))
    if len(indices) == 1:
        axes = [axes]

    for i, idx in enumerate(indices):
        axes[i].imshow(X_test[idx])
        axes[i].axis('off')
        axes[i].set_title(
            f"True: {class_names[y_test[idx]]}\nPred: {class_names[y_pred[idx]]}",
            color=color,
            fontsize=10
        )

    plt.suptitle(title, fontsize=16, fontweight='bold')
    plt.tight_layout(rect=[0, 0, 1, 0.9])

    # Build filename (with timestamp for uniqueness)
    filename = f"{prefix}_examples_{model_name}.svg"
    full_path = f"{save_path}/{filename}"

    # Save and close figure
    plt.savefig(full_path, dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

    print(f"Saved to Google Drive: {full_path}")


print("\n" + "="*60)
print("CLASSIFICATION EXAMPLES")
print("="*60)

# Correct
show_classification_examples(X_test, y_test_eval, pred_1nn, class_names, correct=True, n_examples=5, model_name="1NN")
show_classification_examples(X_test, y_test_eval, pred_3nn, class_names, correct=True, n_examples=5, model_name="3NN")
show_classification_examples(X_test, y_test_eval, pred_ncc, class_names, correct=True, n_examples=5, model_name="NCC")

# Incorrect
show_classification_examples(X_test, y_test_eval, pred_1nn, class_names, correct=False, n_examples=5, model_name="1NN")
show_classification_examples(X_test, y_test_eval, pred_3nn, class_names, correct=False, n_examples=5, model_name="3NN")
show_classification_examples(X_test, y_test_eval, pred_ncc, class_names, correct=False, n_examples=5, model_name="NCC")

"""# **Î£Ï…Î¼Ï€ÎµÏÎ¬ÏƒÎ¼Î±Ï„Î±**"""

print("\n" + "="*60)
print("EXPERIMENTS ANALYSIS")
print("="*60)

# 1. Distance Metrics
print("\nDISTANCE METRICS IMPACT (3-NN):")
print("-" * 50)
euclidean_acc = results['3-NN (Euclidean)']
manhattan_acc = results['3-NN (Manhattan)']
cosine_acc = results['3-NN (Cosine)']

print(f"Euclidean (L2):   {euclidean_acc:.2f}% â† baseline")
print(f"Manhattan (L1):   {manhattan_acc:.2f}% ({manhattan_acc - euclidean_acc:+.2f}%)")
print(f"Cosine (Angular): {cosine_acc:.2f}% ({cosine_acc - euclidean_acc:+.2f}%)")

distances_dict = {'Euclidean': euclidean_acc, 'Manhattan': manhattan_acc, 'Cosine': cosine_acc}
best_distance = max(distances_dict, key=distances_dict.get)
worst_distance = min(distances_dict, key=distances_dict.get)

print(f"\nBest: {best_distance} ({distances_dict[best_distance]:.2f}%)")
print(f"Worst: {worst_distance} ({distances_dict[worst_distance]:.2f}%)")
print(f"Range: {distances_dict[best_distance] - distances_dict[worst_distance]:.2f}%")

# 2. PCA Analysis
print("\nPCA DIMENSIONALITY REDUCTION (1-NN, Euclidean):")
print("-" * 50)
original_acc = results['1-NN (Euclidean)']

print(f"{'Components':<12} {'Accuracy':<12} {'Loss':<10} {'Expl.Var':<12} {'Reduction'}")
print("   " + "-" * 60)

for method in pca_methods:
    pca_info = pca_results[method]
    acc_loss = original_acc - pca_info['accuracy']
    reduction = (3072 - pca_info['n_components']) / 3072 * 100

    print(f"{pca_info['n_components']:<12} {pca_info['accuracy']:>6.2f}%     "
          f"{acc_loss:>5.2f}%    {pca_info['explained_var']:>6.1f}%      {reduction:>5.1f}%")

print(f"{'Original':<12} {original_acc:>6.2f}%     {'0.00%':<10} {'100.0%':<12} {'0.0%'}")
print("   " + "-" * 60)

# Best trade-off
best_pca = min(pca_results.items(),
               key=lambda x: original_acc - x[1]['accuracy'])
print(f"\nBest Trade-off: {best_pca[1]['n_components']} components")
print(f"Accuracy: {best_pca[1]['accuracy']:.2f}%")
print(f"Loss: -{original_acc - best_pca[1]['accuracy']:.2f}%")
print(f"Speedup: ~{3072 / best_pca[1]['n_components']:.1f}x faster")
print(f"Explained Variance: {best_pca[1]['explained_var']:.1f}%")

# 3. Overall Ranking
print("\nOVERALL PERFORMANCE RANKING:")
print("-" * 50)
sorted_methods = sorted(results.items(), key=lambda x: x[1], reverse=True)

for rank, (method, acc) in enumerate(sorted_methods, 1):
    print(f"   {rank:>2}. {method:<30} {acc:>6.2f}%")

"""Î£Ï…Î¼Ï€ÎµÏÎ±ÏƒÎ¼Î±Ï„Î¹ÎºÎ¬:
- Î¿Î¹ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î±Ï€Î¿ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Î´ÎµÎ½ Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ±Î½ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬ Î¿ÏÏ„Îµ Ï„Î·Î½ Î±ÎºÏÎ¯Î²ÎµÎ¹Î±
(accuracy) Î¿ÏÏ„Îµ Ï„Î¿Î½ Ï‡ÏÏŒÎ½Î¿ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚.
- Î¿ 3-NN ÎµÎ¯Î½Î±Î¹ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï‚ Î±Ï€ÏŒ Ï„Î¿Î½ 1-ÎÎ.
- Î¿ NCC Î±Î½ ÎºÎ±Î¹ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï Ï€Î¹Î¿ Î³ÏÎ®Î³Î¿ÏÎ¿Ï‚, Î­Ï‡ÎµÎ¹ Î±ÏÎºÎµÏ„Î¬ Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ¿ accuracy.
- Î¼Îµ Ï„Î·Î½ Ï„ÎµÏ‡Î½Î¹ÎºÎ® PCA Î¼ÎµÎ¹ÏÏƒÎ±Î¼Îµ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬ Ï„Î¿Î½ Ï‡ÏÏŒÎ½Î¿ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ Î¼Îµ Î±Ï€Î¿Î´ÎµÎºÏ„ÏŒ accuracy loss. (Ï€ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿ Î¼Îµ 25 PCA components).
"""